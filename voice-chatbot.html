<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Voice Chatbot</title>
    <!-- Use Tailwind CSS for a modern, responsive design -->
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;700&display=swap');
        body {
            font-family: 'Inter', sans-serif;
            background-color: #f3f4f6;
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
        }
        .chat-container {
            display: flex;
            flex-direction: column;
            width: 100%;
            max-width: 600px;
            height: 80vh;
            border-radius: 1.5rem; /* rounded-3xl */
            background-color: #ffffff;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            overflow: hidden;
        }
        .chat-messages {
            flex-grow: 1;
            overflow-y: auto;
            padding: 1.5rem;
            display: flex;
            flex-direction: column;
            gap: 1rem;
        }
        .message {
            max-width: 80%;
            padding: 0.75rem 1rem;
            border-radius: 1rem;
            word-wrap: break-word; /* Prevents overflow for long words */
        }
        .message.user {
            align-self: flex-end;
            background-color: #2563eb;
            color: #ffffff;
            border-bottom-right-radius: 0.25rem;
        }
        .message.bot {
            align-self: flex-start;
            background-color: #e5e7eb;
            color: #1f2937;
            border-bottom-left-radius: 0.25rem;
        }
        .message img {
            max-width: 100%;
            height: auto;
            border-radius: 0.5rem;
            margin-top: 0.5rem;
        }
        .input-area {
            display: flex;
            padding: 1rem;
            background-color: #f9fafb;
            border-top: 1px solid #e5e7eb;
            gap: 0.5rem;
        }
        .input-area input {
            flex-grow: 1;
            border: 1px solid #d1d5db;
            border-radius: 9999px; /* rounded-full */
            padding: 0.75rem 1.25rem;
            background-color: #ffffff;
            outline: none;
            transition: border-color 0.2s;
        }
        .input-area input:focus {
            border-color: #60a5fa;
        }
        .input-area button {
            padding: 0.75rem;
            border-radius: 9999px; /* rounded-full */
            background-color: #2563eb;
            color: #ffffff;
            display: flex;
            justify-content: center;
            align-items: center;
            transition: background-color 0.2s;
        }
        .input-area button:hover:enabled {
            background-color: #1d4ed8;
        }
        .input-area button:disabled {
            background-color: #9ca3af;
            cursor: not-allowed;
        }
        .icon {
            width: 1.5rem;
            height: 1.5rem;
        }
        .message-box {
            position: fixed;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            background-color: rgba(0, 0, 0, 0.7);
            color: white;
            padding: 20px;
            border-radius: 10px;
            z-index: 1000;
            display: none;
            text-align: center;
        }
        .image-preview {
            max-width: 100px;
            max-height: 100px;
            border-radius: 0.5rem;
            margin-left: 0.5rem;
        }
        @media (max-width: 768px) {
            .chat-container {
                height: 95vh;
                margin: 0.5rem;
            }
        }
    </style>
</head>
<body class="bg-gray-100 flex items-center justify-center min-h-screen p-4">

    <!-- Main chat container -->
    <div class="chat-container">
        <!-- Chat header with a title -->
        <div class="p-4 bg-gray-50 border-b border-gray-200 text-center font-bold text-lg text-gray-800 rounded-t-3xl">
            AI Voice Chatbot
        </div>

        <!-- Chat messages display area -->
        <div id="chat-messages" class="chat-messages">
            <!-- Initial message from the bot -->
            <div class="message bot">
                Hello! I'm a voice-enabled AI assistant. How can I help you today? You can type a message or upload an image.
            </div>
        </div>

        <!-- User input and action buttons -->
        <div class="input-area">
            <input type="file" id="image-input" accept="image/*" class="hidden">
            <input type="text" id="user-input" placeholder="Type your message...">
            <img id="image-preview" class="image-preview hidden">
            
            <button id="image-button" title="Upload Image">
                <svg xmlns="http://www.w3.org/2000/svg" class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                    <rect x="3" y="3" width="18" height="18" rx="2" ry="2"></rect>
                    <circle cx="8.5" cy="8.5" r="1.5"></circle>
                    <polyline points="21 15 16 10 5 21"></polyline>
                </svg>
            </button>
            <button id="send-button" title="Send Message">
                <svg xmlns="http://www.w3.org/2000/svg" class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                    <path d="M22 2L11 13M22 2L15 22L11 13L2 9L22 2Z"/>
                </svg>
            </button>
            <button id="listen-button" title="Start Voice Input">
                <svg xmlns="http://www.w3.org/2000/svg" class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                    <path d="M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3z"/>
                    <path d="M19 10v2a7 7 0 0 1-14 0v-2"/>
                    <line x1="12" y1="19" x2="12" y2="23"/>
                    <line x1="8.5" y1="23" x2="15.5" y2="23"/>
                </svg>
            </button>
            <button id="speak-button" title="Speak Response">
                <svg xmlns="http://www.w3.org/2000/svg" class="icon" viewBox="0 0 24 24" fill="currentColor">
                    <path d="M14.5 10c-.83 0-1.5-.67-1.5-1.5V6c0-.83.67-1.5 1.5-1.5s1.5.67 1.5 1.5v2.5c0 .83-.67 1.5-1.5 1.5zm-3.5 1c1.39 0 2.5-1.11 2.5-2.5V6.5c0-1.39-1.11-2.5-2.5-2.5S8.5 5.11 8.5 6.5V8c0 1.39 1.11 2.5 2.5 2.5zm7-2c-.83 0-1.5-.67-1.5-1.5V6c0-.83.67-1.5 1.5-1.5s1.5.67 1.5 1.5v2.5c0 .83-.67 1.5-1.5 1.5zm-11 5c-.55 0-1 .45-1 1s.45 1 1 1h4c.55 0 1-.45 1-1s-.45-1-1-1h-4zm0 4c-.55 0-1 .45-1 1s.45 1 1 1h4c.55 0 1-.45 1-1s-.45-1-1-1h-4z"/>
                </svg>
            </button>
        </div>
    </div>
    
    <!-- Custom message box for alerts -->
    <div id="message-box" class="message-box"></div>

    <script type="text/javascript">
        // Helper function to show temporary messages
        function showMessage(message) {
            const msgBox = document.getElementById('message-box');
            msgBox.textContent = message;
            msgBox.style.display = 'block';
            setTimeout(() => {
                msgBox.style.display = 'none';
            }, 3000);
        }

        // DOM elements
        const chatMessages = document.getElementById('chat-messages');
        const userInput = document.getElementById('user-input');
        const sendButton = document.getElementById('send-button');
        const listenButton = document.getElementById('listen-button');
        const speakButton = document.getElementById('speak-button');
        const imageInput = document.getElementById('image-input');
        const imageButton = document.getElementById('image-button');
        const imagePreview = document.getElementById('image-preview');

        // State variables for the image and chat history
        let currentImage = null;
        let chatHistory = [{
            role: "model",
            parts: [{ text: "Hello! I'm a voice-enabled AI assistant. How can I help you today? You can type a message or upload an image." }]
        }];

        // Function to append a message to the chat UI
        function appendMessage(role, text, imageUrl = null) {
            const messageDiv = document.createElement('div');
            messageDiv.classList.add('message', role);

            if (imageUrl) {
                const img = document.createElement('img');
                img.src = imageUrl;
                messageDiv.appendChild(img);
            }
            if (text) {
                const textSpan = document.createElement('span');
                textSpan.textContent = text;
                messageDiv.appendChild(textSpan);
            }
            
            chatMessages.appendChild(messageDiv);
            chatMessages.scrollTop = chatMessages.scrollHeight; // Auto-scroll
        }

        // Helper function to convert a file to a base64 string
        function fileToBase64(file) {
            return new Promise((resolve, reject) => {
                const reader = new FileReader();
                reader.readAsDataURL(file);
                reader.onload = () => resolve(reader.result.split(',')[1]);
                reader.onerror = error => reject(error);
            });
        }

        // --- LLM API Call for Text Generation with Image Understanding ---
        async function getGeminiResponse(prompt, imageBase64) {
            const apiUrl = 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20:generateContent';
            const apiKey = ''; // Leave as-is, Canvas will inject the key

            // Construct the payload parts based on whether an image is provided
            let parts = [];
            if (prompt) {
                parts.push({ text: prompt });
            }
            if (imageBase64) {
                parts.push({
                    inlineData: {
                        mimeType: 'image/png', // Assuming PNG, but can be dynamic
                        data: imageBase64
                    }
                });
            }

            if (parts.length === 0) {
                showMessage('Please enter a message or select an image.');
                return;
            }

            // Add the user's message (text and/or image) to chat history
            chatHistory.push({ role: "user", parts: parts });

            const payload = {
                contents: chatHistory
            };

            // Disable buttons and show loading indicator
            sendButton.disabled = true;
            listenButton.disabled = true;
            imageButton.disabled = true;
            appendMessage('bot', 'Typing...');
            const botMessagePlaceholder = chatMessages.lastElementChild;

            try {
                const response = await fetch(`${apiUrl}?key=${apiKey}`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });

                if (!response.ok) {
                    throw new Error(`API error: ${response.statusText}`);
                }

                const result = await response.json();
                
                let botResponseText = 'Sorry, I could not generate a response. Please try again.';
                if (result.candidates && result.candidates.length > 0 &&
                    result.candidates[0].content && result.candidates[0].content.parts &&
                    result.candidates[0].content.parts.length > 0) {
                    botResponseText = result.candidates[0].content.parts[0].text;
                }
                
                // Update the placeholder message with the final response
                botMessagePlaceholder.textContent = botResponseText;
                
                // Add the bot's response to chat history
                chatHistory.push({ role: "model", parts: [{ text: botResponseText }] });

            } catch (error) {
                console.error('Error fetching from Gemini API:', error);
                botMessagePlaceholder.textContent = 'Oops! Something went wrong. Please try again.';
            } finally {
                sendButton.disabled = false;
                listenButton.disabled = false;
                imageButton.disabled = false;
                chatMessages.scrollTop = chatMessages.scrollHeight; // Auto-scroll again
            }
        }

        // --- TTS API Call for Speech Generation ---
        async function speakResponse(text) {
            speakButton.disabled = true;
            const apiUrl = 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent';
            const apiKey = ''; // Leave as-is, Canvas will inject the key
            
            // Function to convert base64 to ArrayBuffer
            function base64ToArrayBuffer(base64) {
                const binaryString = window.atob(base64);
                const len = binaryString.length;
                const bytes = new Uint8Array(len);
                for (let i = 0; i < len; i++) {
                    bytes[i] = binaryString.charCodeAt(i);
                }
                return bytes.buffer;
            }

            // Function to convert PCM audio data to WAV format
            function pcmToWav(pcmData, sampleRate) {
                const pcm16 = new Int16Array(pcmData);
                const buffer = new ArrayBuffer(44 + pcm16.length * 2);
                const view = new DataView(buffer);

                // RIFF identifier
                writeString(view, 0, 'RIFF');
                // RIFF chunk length
                view.setUint32(4, 36 + pcm16.length * 2, true);
                // RIFF type
                writeString(view, 8, 'WAVE');
                // format chunk identifier
                writeString(view, 12, 'fmt ');
                // format chunk length
                view.setUint32(16, 16, true);
                // sample format (raw)
                view.setUint16(20, 1, true);
                // channel count
                view.setUint16(22, 1, true);
                // sample rate
                view.setUint32(24, sampleRate, true);
                // byte rate (sample rate * block align)
                view.setUint32(28, sampleRate * 2, true);
                // block align (channel count * bytes per sample)
                view.setUint16(32, 2, true);
                // bits per sample
                view.setUint16(34, 16, true);
                // data chunk identifier
                writeString(view, 36, 'data');
                // data chunk length
                view.setUint32(40, pcm16.length * 2, true);

                // Write PCM data
                let offset = 44;
                for (let i = 0; i < pcm16.length; i++) {
                    view.setInt16(offset, pcm16[i], true);
                    offset += 2;
                }

                return new Blob([view], { type: 'audio/wav' });

                function writeString(view, offset, string) {
                    for (let i = 0; i < string.length; i++) {
                        view.setUint8(offset + i, string.charCodeAt(i));
                    }
                }
            }

            try {
                const payload = {
                    contents: [{
                        parts: [{ text: text }]
                    }],
                    generationConfig: {
                        responseModalities: ["AUDIO"],
                        speechConfig: {
                            voiceConfig: {
                                prebuiltVoiceConfig: { voiceName: "Kore" }
                            }
                        }
                    },
                    model: "gemini-2.5-flash-preview-tts"
                };

                const response = await fetch(`${apiUrl}?key=${apiKey}`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });
                
                if (!response.ok) {
                    throw new Error(`TTS API error: ${response.statusText}`);
                }

                const result = await response.json();
                const part = result?.candidates?.[0]?.content?.parts?.[0];
                const audioData = part?.inlineData?.data;
                const mimeType = part?.inlineData?.mimeType;

                if (audioData && mimeType && mimeType.startsWith("audio/")) {
                    const sampleRateMatch = mimeType.match(/rate=(\d+)/);
                    const sampleRate = sampleRateMatch ? parseInt(sampleRateMatch[1], 10) : 16000;
                    
                    const pcmData = base64ToArrayBuffer(audioData);
                    const wavBlob = pcmToWav(pcmData, sampleRate);
                    const audioUrl = URL.createObjectURL(wavBlob);
                    
                    const audio = new Audio(audioUrl);
                    audio.play();

                    audio.onended = () => {
                        URL.revokeObjectURL(audioUrl);
                        speakButton.disabled = false;
                    };
                } else {
                    showMessage('TTS response was empty or invalid.');
                    speakButton.disabled = false;
                }
            } catch (error) {
                console.error('Error speaking response:', error);
                showMessage('Failed to speak the response. Please try again.');
                speakButton.disabled = false;
            }
        }

        // Event listener for the "Send" button
        sendButton.addEventListener('click', async () => {
            const userText = userInput.value.trim();
            const imageToSend = currentImage;
            
            if (userText || imageToSend) {
                // Display the user's message with an image if available
                appendMessage('user', userText, imageToSend ? imagePreview.src : null);
                
                // Reset input and image preview
                userInput.value = '';
                imageInput.value = '';
                currentImage = null;
                imagePreview.classList.add('hidden');

                // Call the Gemini API with both text and image
                await getGeminiResponse(userText, imageToSend);
            } else {
                showMessage('Please enter a message or select an image.');
            }
        });

        // Event listener for Enter key in the input field
        userInput.addEventListener('keypress', (event) => {
            if (event.key === 'Enter') {
                sendButton.click();
            }
        });

        // Event listener for the "Listen" button (Speech-to-Text)
        listenButton.addEventListener('click', () => {
            if (!('webkitSpeechRecognition' in window)) {
                showMessage('Speech recognition is not supported in this browser.');
                return;
            }

            const recognition = new webkitSpeechRecognition();
            recognition.lang = 'en-US';
            recognition.interimResults = false;
            recognition.maxAlternatives = 1;

            recognition.onstart = () => {
                listenButton.disabled = true;
                showMessage('Listening...');
            };

            recognition.onresult = (event) => {
                const transcript = event.results[0][0].transcript;
                userInput.value = transcript;
                showMessage('Transcribed.');
                sendButton.click();
            };

            recognition.onerror = (event) => {
                console.error('Speech recognition error:', event.error);
                showMessage(`Error: ${event.error}`);
                listenButton.disabled = false;
            };

            recognition.onend = () => {
                listenButton.disabled = false;
            };

            recognition.start();
        });

        // Event listener for the "Speak" button (Text-to-Speech)
        speakButton.addEventListener('click', () => {
            const lastBotMessage = chatMessages.querySelector('.message.bot:not(:empty)');
            if (lastBotMessage && lastBotMessage.textContent) {
                const textToSpeak = lastBotMessage.textContent;
                speakResponse(textToSpeak);
            } else {
                showMessage('There is no bot response to speak.');
            }
        });

        // Event listener for the "Image" button
        imageButton.addEventListener('click', () => {
            imageInput.click();
        });

        // Event listener for image file selection
        imageInput.addEventListener('change', async (event) => {
            const file = event.target.files[0];
            if (file) {
                // Use FileReader to create a preview and get base64 data
                const reader = new FileReader();
                reader.onload = (e) => {
                    imagePreview.src = e.target.result;
                    imagePreview.classList.remove('hidden');
                };
                reader.readAsDataURL(file);

                // Store base64 data for the API call
                currentImage = await fileToBase64(file);
            }
        });
    </script>
</body>
</html>
